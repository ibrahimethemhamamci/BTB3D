optimizer:
  beta1: 0.0
  beta2: 0.99
  epsilon: 1e-8
  grad_accum_size: 1

lr_scheduler:
  learning_rate: 1e-4
  gen_lr_scale: 1.0
  disc_lr_scale: 0.8
  warmup_steps: 500
data:
  train_dir: /path/to/your/data # a text file, one path per line, refer to image path. eg. /aaa/1.png
  valid_dir: /path/to/your/data
  train_batch_size: 1
  valid_batch_size: 1
  num_workers: 8
  num_epochs: 50
  spatial_size: 512

logging:
  tensorboard_dir: ./exps/tb
  refresh_codebook_tracker_steps: 10
  validate_every_step: 100

io:
  ckpt_base_dir: ./exps/ckpts
  output_base_dir: ./exps/outputs

ema:
  apply_ema: true
  decay_rate: 0.999

gan:
  use_gan: true
  use_lecam_ema: true
  lecam_loss_weight: 0.001
  g_adversarial_loss_weight: 0.1
  d_adversarial_loss_weight: 1.0
  gradient_penalty_cost: 10.0
  generator_loss_type: non-saturating
  discriminator_loss_type: non-saturating
  apply_gradient_penalty: true
  apply_gradient_penalty_every: 20

quantizer:
  commitment_cost: 0.25
  aux_loss_weight: 1.0
  entropy_loss_weight: 0.1
  entropy_loss_scale_factor: 3.0
  entropy_loss_decay_steps: 2000
  diversity_gamma: 1.0
  use_distributed_batch_entropy: true
  
perceptual:
  use_perceptual: false
  ckpt_path: resnet50-11ad3fa6.pth # resnet ckpt path
  perceptual_loss_weight: 0.1

checkpointing:
  inflate_from_2d: false
  inflate_ckpt_path: null 
  pretrained: null
  continue_training: false # set to true if resume all states from previous checkpoint, set to false to only load model checkpoint
  checkpoint_every_step: 500

max_grad_norm: null
recon_loss_weight: 5.0
modal: image
exp_name: train_2d_small_512
